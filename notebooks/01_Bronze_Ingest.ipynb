{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e03639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.logging_utils import setup_logger, log_dataframe_stats\n",
    "\n",
    "# Setup logger\n",
    "logger = setup_logger(__name__, level=\"INFO\")\n",
    "logger.info(\"Starting Bronze layer ingestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session (if not already available in Fabric)\n",
    "# In Fabric, spark session is pre-configured\n",
    "try:\n",
    "    spark\n",
    "    logger.info(\"Using existing Spark session\")\n",
    "except NameError:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Bronze_Ingestion\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "        .getOrCreate()\n",
    "    logger.info(\"Created new Spark session\")\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"../data\"  # Local development\n",
    "# DATA_PATH = \"/lakehouse/default/Files\"  # Fabric Lakehouse path\n",
    "\n",
    "BRONZE_PATH = \"Tables/bronze\"  # Bronze layer path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03235abc",
   "metadata": {},
   "source": [
    "## Task A: Load Customers Data\n",
    "\n",
    "Read the customers CSV file and create a Bronze Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read customers CSV\n",
    "logger.info(\"Reading customers.csv...\")\n",
    "\n",
    "customers_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(f\"{DATA_PATH}/customers.csv\")\n",
    "\n",
    "# Add metadata columns for lineage\n",
    "customers_bronze = customers_raw \\\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp()) \\\n",
    "    .withColumn(\"source_file\", F.lit(\"customers.csv\")) \\\n",
    "    .withColumn(\"bronze_layer_id\", F.monotonically_increasing_id())\n",
    "\n",
    "# Log statistics\n",
    "log_dataframe_stats(customers_bronze, \"customers_bronze\", logger)\n",
    "\n",
    "# Display sample\n",
    "display(customers_bronze.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Delta Lake (Bronze layer)\n",
    "logger.info(\"Writing customers to Bronze Delta table...\")\n",
    "\n",
    "customers_bronze.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{BRONZE_PATH}/customers\")\n",
    "\n",
    "logger.info(\"✓ Customers Bronze table created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f763fd",
   "metadata": {},
   "source": [
    "## Task A: Load Orders Data\n",
    "\n",
    "Read the orders CSV file and create a Bronze Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read orders CSV\n",
    "logger.info(\"Reading orders.csv...\")\n",
    "\n",
    "orders_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(f\"{DATA_PATH}/orders.csv\")\n",
    "\n",
    "# Add metadata columns for lineage\n",
    "orders_bronze = orders_raw \\\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp()) \\\n",
    "    .withColumn(\"source_file\", F.lit(\"orders.csv\")) \\\n",
    "    .withColumn(\"bronze_layer_id\", F.monotonically_increasing_id())\n",
    "\n",
    "# Log statistics\n",
    "log_dataframe_stats(orders_bronze, \"orders_bronze\", logger)\n",
    "\n",
    "# Display sample with various status cases\n",
    "display(orders_bronze.select(\"order_id\", \"customer_id\", \"order_date\", \"status\", \"quantity\", \"price\").limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e55c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Delta Lake (Bronze layer)\n",
    "logger.info(\"Writing orders to Bronze Delta table...\")\n",
    "\n",
    "orders_bronze.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{BRONZE_PATH}/orders\")\n",
    "\n",
    "logger.info(\"✓ Orders Bronze table created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22694c5",
   "metadata": {},
   "source": [
    "## Data Quality Summary\n",
    "\n",
    "Quick analysis of data quality issues in the Bronze layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status value variations (important for Task B)\n",
    "logger.info(\"Analyzing order status values...\")\n",
    "\n",
    "status_distribution = orders_bronze.groupBy(\"status\").count().orderBy(\"status\")\n",
    "display(status_distribution)\n",
    "\n",
    "logger.info(\"⚠️ Note: Status values have different cases (Complete, COMPLETE, complete)\")\n",
    "logger.info(\"   This will be addressed in the Silver layer transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "total_customers = customers_bronze.count()\n",
    "total_orders = orders_bronze.count()\n",
    "\n",
    "print(f\"\"\"\\n{'='*50}\n",
    "Bronze Layer Ingestion Complete\n",
    "{'='*50}\n",
    "Customers ingested: {total_customers}\n",
    "Orders ingested: {total_orders}\n",
    "\n",
    "Next Steps:\n",
    "→ Run notebook 02_Silver_Transform.ipynb to clean and transform data\n",
    "{'='*50}\\n\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
